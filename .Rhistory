library("KernSmooth", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library("KernSmooth", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.packages(KernSmooth)
install.packages(kernsmooth)
install.packages("KernSmooth")
library(KernSmooth)
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(30)
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
install.packackes("swirl")
install.packages("swirl")
library(swirl)
swirl()
head(flags)
dim(flags)
class(flags)
cls_list <- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
cls_vect <- sapply(flags)
cls_vect <- sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flags_colors <- flags[ , 11:17]
flags_colors <- flags[, 11:17]
flag_colors <- flags[, 11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[, 19:23]
lapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3, 4, 5, 5, 5, 6, 6))
unique_vals <- lapply(flag,unique)
unique_vals <- lapply(flags,unique)
unique_vals
sapply(unique_vals, length)
sapply(flags, sapply)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags, unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags, class)
vapply(flags, unique, character(1))
vapply(flags, class, character(1))
?tapply
rm(c(flag_colors, flag_shapes, flag_colors))
rm(c("flag_colors", "flag_shapes"))
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population, flags$landmass, summary)
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
i <- x$getInv()
if(!is.null(i)){
message("returning cached matrix inverse")
return(i)
}
data <- x$get()
i <- solve(data, ...)
x$setInv(i)
i
}
## Put comments here that give an overall description of what your
## functions do
## Write a short comment describing this function
makeCacheMatrix <- function(x = matrix()) {
i <- NULL
set <- function(y) {
m <<- y
i <<- NULL
}
get <- function() m
setInv <- function(inv) i <<- inv
getInv <- function() i
list(set = set, get = get,
setInv = setInv, getInv = getInv)
}
## Write a short comment describing this function
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
i <- x$getInv()
if(!is.null(i)){
message("returning cached matrix inverse")
return(i)
}
data <- x$get()
i <- solve(data, ...)
x$setInv(i)
i
}
m <- matrix(c(1,3,9,3,9,3,9,3,1),nrow=3,ncol=3)
makeCacheMatrix(m)
mMatrix <- makeCacheMatrix(m)
cacheSolve(mMatrix)
cacheSolve(mMatrix)
makeCacheMatrix()
m <- makeCacheMatrix()
m
m$get
m <- matrix(c(1,3,9,3,9,3,9,3,1),nrow=3,ncol=3)
m$get
m$get()
m <- makeCacheMatrix(m)
m$get
m$get()
m
m$get
m <- matrix(c(1,3,9,3,9,3,9,3,1),nrow=3,ncol=3)
makeCacheMatrix(m)
mMatrix<-makeCacheMatrix(m)
mMatrix$get
mMatrix$get()
empty <- makeCacheMatrix()
empty$get
empty$get()
environment(x)
environment(m)
nchar("cd051b6eded4ea36bcf3ed88c2efd8441e47e2db")
library(datasets)
data(iris)
?iris
iris
lapply(iris,class)
dim(iris)
mean(iris$Sepal.Length)
mean(iris$Sepal.Length, na.rm=F)
mean(iris$Sepal.Length, na.rm=T)
apply(iris,mean)
apply
?apply
apply(iris,1:4,mean)
apply(iris, 2, mean)
lapply(iris,mean)
apply(iris,1,mean)
apply(iris,2,mean)
apply(iris[1:4,],2,mean)
apply(iris[1:4,],1,mean)
apply(iris,2,mean)
apply(iris[,1:4],2,mean)
apply(iris[,1:4],1,mean)
library(datasets)
data(mtcars)
?mtcars
mtcars
lapply(mtcars,class)
sapply(mtcars,class)
split(mtcars,mpg)
split(mtcars,mtcars$mpg)
x<-split(mtcars,mtcars$mpg)
x
rm(x)
split(mtcars,2)
?split
split(mtcars,mtcars$cyl)
sapply(split(mtcars,mtcars$cyl),mean)
sapply(split(mtcars$mpg,mtcars$cyl),mean)
cylMean<-sapply(split(mtcars$mpg,mtcars$cyl),mean)
cylMean
cylMean$4
cylMean[1]
cylMean[3]-cylMean[1]
debug(ls)
ls
exit()
debug(ls)
ls()
library(datasets)
data(iris)
split(iris$Sepal.Length,"virginica")
mean(split(iris$Sepal.Length,"virginica"))
mean(split(iris$Sepal.Length,"virginica"), rm.na=F)
split(iris$Sepal.Length,"virginica")
vtemp<-split(iris$Sepal.Length,"virginica")
vtemp
mean(vtemp)
class(vtemp)
sapply(split(iris$Sepal.Length,"virginica"),mean)
sapply(iris$Sepal.Length,mean,na.rm=F)
vtemp<-iris[iris$Species=="virginica",iris$Sepal.Length]
vtemp<-iris[iris$Species=="virginica","Sepal.Length"]
vtemp
mean(vtemp)
View(iris)
split(iris,iris$Species)
as.factors(iris$Species)
levels(iris$Species)
split(iris$Sepal.Length,levels(iris$Species))
sapply(split(iris$Sepal.Length,levels(iris$Species)),mean)
sapply(split(iris$Sepal.Length,levels(iris$Species)),mean,na.rm=F)
sapply(split(iris$Sepal.Length,levels(iris$Species)),mean,na.rm=T)
iris[iris$Species=="virginica",]
virginoca<-iris[iris$Species=="virginica",]
virginoca$Sepal.Length
mean(virginoca$Sepal.Length)
summary(virginoca$Sepal.Length)
sapply(split(iris$Sepal.Length,levels(iris$Species)),summary)
apply(split(iris$Sepal.Length,levels(iris$Species)),summary)
lapply(split(iris$Sepal.Length,levels(iris$Species)),summary)
data(mtcars)
tapply(mtcars$mpg, mtcars$cyl, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
hpCyl<-tapply(mtcars$hp, mtcars$cyl, mean)
hpCyl[3]-hpCyl[1]
hpCyl
hpCyl[1]
hpCyl[3]
abs(hpCyl[3]-hpCyl[1])
tapply(iris$Sepal.Length,iris$Species)
tapply(mean,iris$Sepal.Length,iris$Species)
tapply(iris$Sepal.Length,iris$Species,mean)
sapply(split(iris$Sepal.Length,levels(iris$Species)),summary)
mean(virginoca$Sepal.Length)
mean(iris[iris$Species=="virginica",])
mean(iris[iris$Species=="virginica","Sepal.Length"])
sapply(split(iris$Sepal.Length,levels(iris$Species)),mean)
lapply(split(iris$Sepal.Length,levels(iris$Species)),summary)
lapply(split(iris$Sepal.Length,levels(iris$Species)),mean)
install.packages("xslx")
setwd("~/Google Drive/Education/Coursera/datasciencecoursera/getdata-034/project")
install.packages("readr") # Faster alternative to read.fwf
library(readr)
labels <- read.delim("UCIdataset/activity_labels.txt", header = F, stringsAsFactors = F, sep = " ")
Ytrain <- read.csv2("UCIdataset/train/y_train.txt", header = F, stringsAsFactors = F)
Ytest <- read.csv2("UCIdataset/test/y_test.txt", header = F, stringsAsFactors = F)
Ymerge <- rbind(Ytrain, Ytest)
Ymerge <- merge(Ymerge, labels, by.x = "V1", by.y = "V1")
colnames(Ymerge) <- c("activityCode", "activityName")
activityName <- Ymerge[,2]
features <- read.delim("UCIdataset/features.txt", header = F, stringsAsFactors = F, sep = " ")
necCols <- grepl("std|mean\\(", features[,2], ignore.case = F)
features <- features[which(necCols==T),]
features <- as.vector(features[,2])
features
Xtrain <- read_fwf("UCIdataset/train/X_train.txt", fwf_widths(c(rep(c(1,15), 561))))
Xtest <- read_fwf("UCIdataset/test/X_test.txt", fwf_widths(c(rep(c(1,15), 561))))
Xmerge <- rbind(Xtrain, Xtest)
Xmerge <- Xmerge[,-seq(1,1122,2)]
Xmerge <- Xmerge[, which(necCols == T)]
colnames(Xmerge) <- features
subtrain <- read.csv2("UCIdataset/train/subject_train.txt", header = F)
subtest <- read.csv2("UCIdataset/test/subject_test.txt", header = F)
submerge <- rbind(subtrain, subtest)
colnames(submerge) <- "subject"
finaldata_short <- cbind(submerge, activityName, Xmerge)
melted <- melt(finaldata_short, id = c("subject", "activityName"), variables = features)
casted <- dcast(melted, subject + activityName ~ variable,mean)
library("reshape2", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
melted <- melt(finaldata_short, id = c("subject", "activityName"), variables = features)
casted <- dcast(melted, subject + activityName ~ variable,mean)
View(casted)
finaldata <- cbind(submerge, activityName, Xmerge)
melted <- melt(finaldata, id = c("subject", "activityName"), variables = features)
casted <- dcast(melted, subject + activityName ~ variable,mean)
rm(finaldata_short)
### Quality assurance checks
# Determine which activities each subject conducted
subjectActivity <- cbind(submerge, Ymerge)
dcast(subjectActivity)
dcast(subjectActivity, subject ~ activityCode)
# Spot check whether manual calculations of 1 subejct matched casted results
sub1 <- finaldata[finaldata$subject == 1, ]
sub1mean <- sapply(sub1[,features], mean)
casted1 <- casted[casted$subject == 1, features]
casted1 == sub1mean
sub15 <- finaldata[finaldata$subject == 15, ]
sub15mean <- sapply(sub15[,features], mean)
casted15 <- casted[casted$subject == 15, features]
casted15 == sub15mean
dcast(subjectActivity, subject ~ activityName)
setwd("~/Google Drive/Education/Coursera/datasciencecoursera/getdata-034/project")
labels <- read.delim("UCIdataset/activity_labels.txt", header = F, stringsAsFactors = F, sep = " ")
Ytrain <- read.csv2("UCIdataset/train/y_train.txt", header = F, stringsAsFactors = F)
Ytest <- read.csv2("UCIdataset/test/y_test.txt", header = F, stringsAsFactors = F)
Ymerge <- rbind(Ytrain, Ytest)
Ymerge <- merge(Ymerge, labels, by.x = "V1", by.y = "V1")
colnames(Ymerge) <- c("activityCode", "activityName")
activityName <- Ymerge[,2]
rm(list = c("sub15mean", "sub1mean", "casted1", "casted15", "subjectActivity"))
# rm(list = c("sub1", "sub15", "sub15mean", "sub1mean", "casted1", "casted15", "subjectActivity"))
rm(list = c("sub1", "sub15", "sub15mean", "sub1mean", "casted1", "casted15", "subjectActivity"))
?write.csv
write.table(casted, file = "./subject_activity_means.txt", row.names = F)
features <- read.delim("UCIdataset/features.txt", header = F, stringsAsFactors = F, sep = " ")
features
xtrain
Xtrain
sapply(Xtrain,summary)
sapply(Xtrain$V1,summary)
summary(Ytest)
summary(subtest)
summary(subtrain)
sapply(subtest,length)
tapply(subtest,length)
table(subtest)
table(subtrain)
levels(finaldata$activityName)
Ytrain <- read.csv2("./train/y_train.txt", header = F, stringsAsFactors = F)
setwd("~/Google Drive/Education/Coursera/getdata034-project")
Ytrain <- read.csv2("./train/y_train.txt", header = F, stringsAsFactors = F)
Ytest <- read.csv2("./test/y_test.txt", header = F, stringsAsFactors = F)
Ymerge <- rbind(Ytrain, Ytest)
labels <- read.delim("./activity_labels.txt", header = F, stringsAsFactors = F, sep = " ")
Ymerge <- merge(Ymerge, labels, by.x = "V1", by.y = "V1")
# colnames(Ymerge) <- c("activityCode", "activityName")
activityName <- Ymerge[,2]
### Reading in features & X data; isolating only necessary feature columns
features <- read.delim("./features.txt", header = F, stringsAsFactors = F, sep = " ")
necCols <- grepl("std|mean\\(", features[,2], ignore.case = F)
features <- features[which(necCols==T),]
features <- as.vector(features[,2])
Xtrain <- read_fwf("./train/X_train.txt", fwf_widths(c(rep(c(1,15), 561))))
Xtest <- read_fwf("./test/X_test.txt", fwf_widths(c(rep(c(1,15), 561))))
Xmerge <- rbind(Xtrain, Xtest)
Xmerge <- Xmerge[,-seq(1,1122,2)]
Xmerge <- Xmerge[, which(necCols == T)]
colnames(Xmerge) <- features
### Subject reading & aggregating
subtrain <- read.csv2("./train/subject_train.txt", header = F)
subtest <- read.csv2("./test/subject_test.txt", header = F)
submerge <- rbind(subtrain, subtest)
colnames(submerge) <- "subject"
### Merging into finl dataset
# finaldata_long <- cbind(submerge, Ymerge, Xmerge)
finaldata <- cbind(submerge, activityName, Xmerge)
### Reshaping aggregated dataset
melted <- melt(finaldata, id = c("subject", "activityName"), variables = features)
casted <- dcast(melted, subject + activityName ~ variable,mean)
### Write casted dataset to .txt for submission
write.table(casted, file = "./subject_activity_means.txt", row.names = F)
casted
